{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unt-iialab/INFO5731_Spring2020/blob/master/Assignments/INFO5731_Assignment_Four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
        "\n",
        "1. Features (text representation) used for topic modeling.\n",
        "\n",
        "2. Top 10 clusters for topic modeling.\n",
        "\n",
        "3. Summarize and describe the topic for each cluster.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYz9d0OndHQW",
        "outputId": "bfc13e7e-6e1e-46f3-e632-db4d5c3226de"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertopic\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDZ0HRv0dVRS",
        "outputId": "436c6166-f807-4ccf-aedd-b1d767e303ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bertopic\n",
            "  Downloading bertopic-0.16.1-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/158.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/158.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.5/158.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.25.2)\n",
            "Collecting hdbscan>=0.8.29 (from bertopic)\n",
            "  Downloading hdbscan-0.8.33.tar.gz (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting umap-learn>=0.5.0 (from bertopic)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.2)\n",
            "Collecting sentence-transformers>=0.4.1 (from bertopic)\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.15.0)\n",
            "Collecting cython<3,>=0.27 (from hdbscan>=0.8.29->bertopic)\n",
            "  Using cached Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (24.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.40.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (9.4.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.58.1)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
            "  Downloading pynndescent-0.5.12-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (4.11.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (0.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.33-cp310-cp310-linux_x86_64.whl size=3039274 sha256=43a4f257ec9b3ca77a4ad510544a484bcd233b739c8d1a40a880be16525a9e77\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/0b/3b/dc4f60b7cc455efaefb62883a7483e76f09d06ca81cf87d610\n",
            "Successfully built hdbscan\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, cython, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pynndescent, nvidia-cusolver-cu12, hdbscan, umap-learn, sentence-transformers, bertopic\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 3.0.10\n",
            "    Uninstalling Cython-3.0.10:\n",
            "      Successfully uninstalled Cython-3.0.10\n",
            "Successfully installed bertopic-0.16.1 cython-0.29.37 hdbscan-0.8.33 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pynndescent-0.5.12 sentence-transformers-2.7.0 umap-learn-0.5.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab85857-396a-4f13-d8f2-946cd2e855fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 clusters for topic modeling:\n",
            "Cluster 1: film, movie, im, fight, watched, ending, violence, tyler, club, people\n",
            "Cluster 2: movie, book, love, psychological, consumerism, understand, reveal, point, club, way\n",
            "Cluster 3: movie, film, fight, club, like, time, great, life, good, tyler\n",
            "Cluster 4: movie, club, film, like, message, clever, ending, im, think, fight\n",
            "Cluster 5: movie, like, half, twist, bad, film, bonham, dialogue, woman, black\n",
            "Cluster 6: movie, film, tyler, narrator, fight, club, people, jack, like, really\n",
            "Cluster 7: movie, film, say, club, fight, people, like, level, seen, person\n",
            "Cluster 8: ordinary, clothes, movie, drive, talk, camera, work, good, film, watch\n",
            "Cluster 9: oscar, bored, movie, lot, make, way, rule, piece, thing, film\n",
            "Cluster 10: fighting, finish, funny, watch, time, absolute, movie, drama, simply, film\n",
            "Cluster 1:\n",
            "film movie im fight watched ending violence tyler club people\n",
            "Cluster 2:\n",
            "movie book love psychological consumerism understand reveal point club way\n",
            "Cluster 3:\n",
            "movie film fight club like time great life good tyler\n",
            "Cluster 4:\n",
            "movie club film like message clever ending im think fight\n",
            "Cluster 5:\n",
            "movie like half twist bad film bonham dialogue woman black\n",
            "Cluster 6:\n",
            "movie film tyler narrator fight club people jack like really\n",
            "Cluster 7:\n",
            "movie film say club fight people like level seen person\n",
            "Cluster 8:\n",
            "ordinary clothes movie drive talk camera work good film watch\n",
            "Cluster 9:\n",
            "oscar bored movie lot make way rule piece thing film\n",
            "Cluster 10:\n",
            "fighting finish funny watch time absolute movie drama simply film\n",
            "\n",
            "Describing topic for each cluster:\n",
            "\n",
            "Topic for cluster 1: The Movie Fight Club\n",
            "Topic for cluster 2: Themes\n",
            "Topic for cluster 3: Enjoiyment\n",
            "Topic for cluster 4: Analysis\n",
            "Topic for cluster 5: Specific Scenes and characters\n",
            "Topic for cluster 6: Focus on Tyler\n",
            "Topic for cluster 7: General sentiment\n",
            "Topic for cluster 8: Comparisions\n",
            "Topic for cluster 9: Awards and critical reception\n",
            "Topic for cluster 10: Movie's genre\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/drive/MyDrive/annotated_reviews.csv\"\n",
        "data = pd.read_csv(file_path)  # Load dataset from the specified file path\n",
        "\n",
        "# Defining text representation (TF-IDF vectorization)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000, stop_words='english')\n",
        "\n",
        "# Defining topic modeling algorithm (LDA)\n",
        "lda_model = LatentDirichletAllocation(n_components=10, max_iter=5, learning_method='online', learning_offset=50., random_state=0)\n",
        "\n",
        "# Create a pipeline for topic modeling\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', tfidf_vectorizer),\n",
        "    ('lda', lda_model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the data\n",
        "pipeline.fit(data['Clean_Text'])\n",
        "\n",
        "#2) Top 10 clusters for topic modeling\n",
        "\n",
        "# Extracting top words for each cluster\n",
        "def get_top_words(model, feature_names, n_top_words):\n",
        "    top_words = []\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        top_words.append([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
        "    return top_words\n",
        "\n",
        "n_top_words = 10\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "top_words = get_top_words(lda_model, feature_names, n_top_words)\n",
        "\n",
        "# Print top 10 clusters for topic modeling\n",
        "print(\"\\nTop 10 clusters for topic modeling:\")\n",
        "for i, words in enumerate(top_words):\n",
        "    print(f\"Cluster {i+1}: {', '.join(words)}\")\n",
        "\n",
        "# 3)Summarize and describe the topic for each cluster.\n",
        "# Define a function to summarize each cluster\n",
        "def summarize_clusters(top_words):\n",
        "    cluster_summaries = {}\n",
        "    for i, words in enumerate(top_words):\n",
        "        summary = f\"Cluster {i+1}:\\n{' '.join(words)}\"\n",
        "        cluster_summaries[f'Cluster {i+1}'] = summary\n",
        "    return cluster_summaries\n",
        "cluster_summaries = summarize_clusters(top_words)\n",
        "\n",
        "# Print summaries for each cluster\n",
        "for cluster, summary in cluster_summaries.items():\n",
        "  print(summary)\n",
        "\n",
        "#Inferring Topic for each cluster from keywords\n",
        "print(\"\\nDescribing topic for each cluster:\" )\n",
        "print(\"\\nTopic for cluster 1: The Movie Fight Club\")\n",
        "print(\"Topic for cluster 2: Themes\")\n",
        "print(\"Topic for cluster 3: Enjoiyment\")\n",
        "print(\"Topic for cluster 4: Analysis\")\n",
        "print(\"Topic for cluster 5: Specific Scenes and characters\")\n",
        "print(\"Topic for cluster 6: Focus on Tyler\")\n",
        "print(\"Topic for cluster 7: General sentiment\")\n",
        "print(\"Topic for cluster 8: Comparisions\")\n",
        "print(\"Topic for cluster 9: Awards and critical reception\")\n",
        "print(\"Topic for cluster 10: Movie's genre\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "1. Select features for the sentiment classification and explain why you select these features. Use a markdown cell to provide your explanation.\n",
        "\n",
        "2. Select two of the supervised learning algorithms/models from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build two sentiment classifiers respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
        "\n",
        "3. Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. The test set must be used for model evaluation in this step. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Selection:**\n",
        "\n",
        "In this code I used TF-IDF features.\n",
        "For sentiment classification, the code makes use of TF-IDF (Term Frequency-Inverse Document Frequency) features. TF-IDF is chosen for sentiment analysis tasks because it effectively balances simplicity and effectiveness, captures the relative importance of words in the document compared to the entire corpus, and aids in managing common words that appear frequently."
      ],
      "metadata": {
        "id": "D0ZHMwmTce7s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "vATjQNTY8buA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb1b67bf-14b0-4105-b812-2a03b74d3ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Cross-validation Scores (5-fold):\n",
            "SVM: 0.7134817844429296\n",
            "Random Forest: 0.7171248958570022\n",
            "\n",
            "Evaluation Metrics:\n",
            "SVM Classifier:\n",
            "Accuracy: 0.7254901960784313\n",
            "Precision: 0.7148478701825557\n",
            "Recall: 0.7254901960784313\n",
            "F1 Score: 0.6832676611314382\n",
            "\n",
            "Random Forest Classifier:\n",
            "Accuracy: 0.696078431372549\n",
            "Precision: 0.683546096034042\n",
            "Recall: 0.696078431372549\n",
            "F1 Score: 0.6356062940235019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/annotated_reviews.csv')\n",
        "\n",
        "# Prepare features and target\n",
        "X = data['Clean_Text']\n",
        "y = data['sentiment']\n",
        "\n",
        "# Splitting the dataset into training(80%) and testing sets(20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "# Transform the text data into TF-IDF features\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Initialize classifiers\n",
        "svm_classifier = SVC()\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "# Train the classifiers\n",
        "svm_classifier.fit(X_train_tfidf, y_train)\n",
        "rf_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Evaluate classifiers using cross-validation (5-fold)\n",
        "svm_scores = cross_val_score(svm_classifier, X_train_tfidf, y_train, cv=5)\n",
        "rf_scores = cross_val_score(rf_classifier, X_train_tfidf, y_train, cv=5)\n",
        "\n",
        "# Print mean cross-validation scores\n",
        "print(\"Mean Cross-validation Scores (5-fold):\")\n",
        "print(\"SVM:\", svm_scores.mean())\n",
        "print(\"Random Forest:\", rf_scores.mean())\n",
        "\n",
        "# Predict on the test set\n",
        "svm_predictions = svm_classifier.predict(X_test_tfidf)\n",
        "rf_predictions = rf_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Calculate metrics for SVM classifier\n",
        "svm_accuracy, svm_precision, svm_recall, svm_f1 = calculate_metrics(y_test, svm_predictions)\n",
        "\n",
        "# Calculate metrics for Random Forest classifier\n",
        "rf_accuracy, rf_precision, rf_recall, rf_f1 = calculate_metrics(y_test, rf_predictions)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(\"SVM Classifier:\")\n",
        "print(\"Accuracy:\", svm_accuracy)\n",
        "print(\"Precision:\", svm_precision)\n",
        "print(\"Recall:\", svm_recall)\n",
        "print(\"F1 Score:\", svm_f1)\n",
        "\n",
        "print(\"\\nRandom Forest Classifier:\")\n",
        "print(\"Accuracy:\", rf_accuracy)\n",
        "print(\"Precision:\", rf_precision)\n",
        "print(\"Recall:\", rf_recall)\n",
        "print(\"F1 Score:\", rf_f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(20 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878.\n",
        "\n",
        "1. Conduct necessary Explatory Data Analysis (EDA) and data cleaning steps on the given dataset. Split data for training and testing.\n",
        "2. Based on the EDA results, select a number of features for the regression model. Shortly explain why you select those features.\n",
        "3. Develop a regression model. The train set should be used.\n",
        "4. Evaluate performance of the regression model you developed using appropriate evaluation metrics. The test set should be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "XfvMKJjIXS5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a316eb83-c645-4e5d-b01d-cbee58234ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Shape: (1460, 81)\n",
            "Testing Data Shape: (1459, 80)\n",
            "\n",
            "Missing Values in Training Data:\n",
            "Id                 0\n",
            "MSSubClass         0\n",
            "MSZoning           0\n",
            "LotFrontage      259\n",
            "LotArea            0\n",
            "                ... \n",
            "MoSold             0\n",
            "YrSold             0\n",
            "SaleType           0\n",
            "SaleCondition      0\n",
            "SalePrice          0\n",
            "Length: 81, dtype: int64\n",
            "\n",
            "Missing Values in Testing Data:\n",
            "Id                 0\n",
            "MSSubClass         0\n",
            "MSZoning           4\n",
            "LotFrontage      227\n",
            "LotArea            0\n",
            "                ... \n",
            "MiscVal            0\n",
            "MoSold             0\n",
            "YrSold             0\n",
            "SaleType           1\n",
            "SaleCondition      0\n",
            "Length: 80, dtype: int64\n",
            "\n",
            "Model Evaluation:\n",
            "Mean Squared Error (MSE): 1.114450241175553e-21\n",
            "Root Mean Squared Error (RMSE): 3.338338271019809e-11\n",
            "R-squared (R2): 1.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the training and testing datasets\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/test.csv\")\n",
        "\n",
        "# Check the shape of the datasets\n",
        "print(\"Training Data Shape:\", train_data.shape)\n",
        "print(\"Testing Data Shape:\", test_data.shape)\n",
        "# 1) EDA Analysis\n",
        "\n",
        "# Check for missing values in the training and testing dataset\n",
        "print(\"\\nMissing Values in Training Data:\")\n",
        "print(train_data.isnull().sum())\n",
        "print(\"\\nMissing Values in Testing Data:\")\n",
        "print(test_data.isnull().sum())\n",
        "\n",
        "# Fill missing values in training and tesing data\n",
        "train_data.fillna(train_data.select_dtypes(include=[np.number]).mean(), inplace=True)\n",
        "test_data.fillna(test_data.select_dtypes(include=[np.number]).mean(), inplace=True)\n",
        "# Select numerical features for analysis\n",
        "numerical_features = train_data.select_dtypes(include=[np.number])\n",
        "# Check correlations among numerical features\n",
        "correlation_matrix = numerical_features.corr()\n",
        "\n",
        "# 2) Feature selection\n",
        "# Select features based on correlation with the target variable\n",
        "selected_features = correlation_matrix['SalePrice'].sort_values(ascending=False)[:10].index\n",
        "# Add additional features if necessary based on domain knowledge\n",
        "selected_features = selected_features.tolist() + ['OverallQual', 'GrLivArea']\n",
        "# Prepare X and y for training\n",
        "X_train = train_data[selected_features]\n",
        "y_train = train_data['SalePrice']\n",
        "# Split data for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3) Building the regression model\n",
        "# Train the regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# Make predictions on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 4) Evaluationg model's performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"R-squared (R2):\", r2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Based on the EDA results, select a number of features for the regression model. Shortly explain why you select those features.**\n",
        "The features included in the regression model are chosen with consideration for domain knowledge and their correlation with the target variable, \"SalePrice.\" Here's a quick justification for the choice:\n",
        "OverallQual: The house's sale price is probably going to be significantly influenced by its overall quality. Buyers frequently take this crucial but arbitrary feature into consideration.\n",
        "GrLivArea: A house's price is largely influenced by its above-ground living area. Prices for larger living areas are typically higher.\n",
        "Other attributes chosen in accordance with correlation: Because of their comparatively high positive correlation with the sale price, these features were selected. It is anticipated that features with stronger correlations will be more predictive in determining the sale price."
      ],
      "metadata": {
        "id": "WHTYRLVitMeH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BbswDvnEX-k"
      },
      "source": [
        "# **Question 4: Using Pre-trained LLMs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKwKTnW1EX-k"
      },
      "source": [
        "(20 points)\n",
        "Utilize a **Pre-trained Language Model (PLM) from the Hugging Face Repository** for predicting sentiment polarities on the data you collected in Assignment 3.\n",
        "\n",
        "Then, choose a relevant LLM from their repository, such as GPT-3, BERT, or RoBERTa or any other related models.\n",
        "1. (5 points) Provide a brief description of the PLM you selected, including its original pretraining data sources,  number of parameters, and any task-specific fine-tuning if applied.\n",
        "2. (10 points) Use the selected PLM to perform the sentiment analysis on the data collected in Assignment 3. Only use the model in the **zero-shot** setting, NO finetuning is required. Evaluate performance of the model by comparing with the groundtruths (labels you annotated) on Accuracy, Precision, Recall, and F1 metrics.\n",
        "3. (5 points) Discuss the advantages and disadvantages of the selected PLM, and any challenges encountered during the implementation. This will enable a comprehensive understanding of the chosen LLM's applicability and effectiveness for the given task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.**Provide a brief description of the PLM you selected, including its original pretraining data sources, number of parameters, and any task-specific fine-tuning if applied**\n",
        "\n",
        "A pre-trained language model created by Google is called Bidirectional Encoder Representations from Transformers, or BERT. It was trained using the transformer architecture on a sizable corpus of text data from multiple sources, such as BooksCorpus and the English Wikipedia. Contextual information can be extracted from text in both directions using BERT, which has about 110 million parameters.\n",
        "BERT can be used in a zero-shot setting in sentiment analysis, leveraging its pre-trained knowledge to predict sentiment polarities without the need for task-specific fine-tuning, or it can be optimally tuned on particular sentiment classification tasks. With no need for additional training on labeled data unique to each task, BERT's zero-shot approach enables it to generalize well to a variety of sentiment analysis tasks."
      ],
      "metadata": {
        "id": "JGOms4UFtuat"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "BJgHWnOhFm-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a4d0d0-108a-4528-970c-0000b0567772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.017699115044247787\n",
            "Precision: 0.0058997050147492625\n",
            "Recall: 0.3333333333333333\n",
            "F1 Score: 0.011594202898550725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/annotated_reviews.csv')\n",
        "\n",
        "# Extract text and ground truth labels from your dataset\n",
        "texts = data['Clean_Text'].tolist()\n",
        "ground_truths = data['sentiment'].tolist()\n",
        "\n",
        "# Initialize BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define function to perform sentiment analysis\n",
        "def sentiment_analysis(text):\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer.encode_plus(text, return_tensors='pt', truncation=True, max_length=512)\n",
        "    # Perform inference\n",
        "    outputs = model(**inputs)\n",
        "    # Apply softmax to get probabilities\n",
        "    probabilities = outputs.logits.softmax(dim=1)\n",
        "    # Choose the class with the highest probability as the predicted label\n",
        "    predicted_label = probabilities.argmax().item()\n",
        "    return predicted_label\n",
        "\n",
        "# Perform sentiment analysis on the data\n",
        "predictions = [sentiment_analysis(text) for text in texts]\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode ground truth labels into numerical format\n",
        "encoded_ground_truths = label_encoder.fit_transform(ground_truths)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(encoded_ground_truths, predictions)\n",
        "precision = precision_score(encoded_ground_truths, predictions, average='macro')\n",
        "recall = recall_score(encoded_ground_truths, predictions, average='macro')\n",
        "f1 = f1_score(encoded_ground_truths, predictions, average='macro')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Discuss the advantages and disadvantages of the selected PLM, and any challenges encountered during the implementation. This will enable a comprehensive understanding of the chosen LLM's applicability and effectiveness for the given task.**\n",
        "\n",
        "\n",
        "\n",
        "**Advantages of BERT:**\n",
        "1) High performance: BERT performs exceptionally well on NLP tasks such as sentiment analysis because it can capture contextual information well, which leads to improved text comprehension and sentiment classification accuracy.\n",
        "2) Transfer learning: Due to its extensive pre-training on text data, BERT is able to learn general language, which facilitates effective sentiment analysis fine-tuning with a reduced number of labeled examples. This is especially useful in situations where data is scarce.\n",
        "3) Many languages and domains have demonstrated the robustness of BERT. It can process many different kinds of text inputs, such as lengthy documents, brief sentences, and even raucous or colloquial language that is frequently seen in online forums and customer reviews.\n",
        "\n",
        "**Disadvantages:**\n",
        "1) Because of its high computational requirements, BERT is expensive to fine-tune and infer. This is especially problematic in environments with limited resources, such as mobile or edge devices that handle big datasets.\n",
        "2) Because of its high computational requirements, BERT is expensive to fine-tune and infer. This is especially problematic in environments with limited resources, such as mobile or edge devices that handle big datasets.\n",
        "\n",
        "**Challenges:**\n",
        "Overcoming the challenges of data preprocessing, optimizing hyperparameters for peak performance, and deciding on relevant assessment metrics to precisely determine model efficacy are all necessary steps in putting BERT into practice for sentiment analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "gONQbGDhuEfz"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}